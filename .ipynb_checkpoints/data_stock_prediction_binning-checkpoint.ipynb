{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#import statsmodels.tsa.seasonal as smt\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import random\n",
    "import datetime as dt\n",
    "from sklearn import linear_model \n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "import os\n",
    "data_path = \"/notebooks/stock_data_analysis/data_2/Stocks\"\n",
    "os.chdir(data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/notebooks/stock_data_analysis/data_2/Stocks'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "# kernels let us navigate through the zipfile as if it were a directory\n",
    "\n",
    "# trying to read a file of size zero will throw an error, so skip them\n",
    "filenames = [x for x in os.listdir(data_path) if x.endswith('.txt') and os.path.getsize(x) > 0]\n",
    "# = random.sample(filenames,1)\n",
    "#print(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def data_normalize(df, col):\n",
    "    data_close = np.reshape(df[col], (df[col].shape[0], 1))\n",
    "    scaler = MinMaxScaler()\n",
    "    result_get = scaler.fit_transform(data_close)\n",
    "    return result_get\n",
    "\n",
    "def binning_data(data, num_embedding = 1000):\n",
    "    bins = np.linspace(0, 1, num_embedding)\n",
    "    inds = np.digitize(data_get, bins)\n",
    "    return inds\n",
    "\n",
    "\n",
    "def get_data(file_name):\n",
    "    file_name = os.path.join('/notebooks/stock_data_analysis/data_2/Stocks', file_name)\n",
    "    df = pd.read_csv(file_name, sep=',')\n",
    "    #combine attributes\n",
    "    #combine high and low by avg\n",
    "    #combine open and close by avg\n",
    "    #combine avgHighLow and avgOpenClose\n",
    "    df['Price'] = (df['High'] + df['Low'] + df['Open'] + df['Close'])/4\n",
    "    #take log as this flattens the data more, resulting in a better prediction\n",
    "    df['Price'] = np.log(df['Price'])\n",
    "\n",
    "    #drop obsolete columns for faster processing\n",
    "    columns2Drop = [] #['High', 'Low', 'Open', 'Close', 'OpenInt']\n",
    "    df = df.drop(labels=columns2Drop, axis=1)\n",
    "\n",
    "    #create new attribute of \"movement\"\n",
    "    df['Volume*Price'] = df['Volume'] * df['Price']\n",
    "    # print(df)\n",
    "\n",
    "    label = filename\n",
    "    df['Label'] = label\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    #conver data to an number so we can fit it to LinearRegression()\n",
    "#     df['Date'] = df['Date'].map(dt.datetime.toordinal)\n",
    "\n",
    "    #data.append(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(data_path):\n",
    "    with open(data_path, 'rb') as handle:\n",
    "        data_get = pickle.load(handle)\n",
    "    return data_get\n",
    "\n",
    "def save_picle(data_path, data):\n",
    "    with open(data_path, 'wb') as handle:\n",
    "        pickle.dump(data, handle)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exists(path):\n",
    "    \"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\n",
    "    try:\n",
    "        st = os.stat(path)\n",
    "    except os.error:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathModel = os.getcwd()  #\n",
    "embedding_col_path = os.path.join(pathModel, \"data_get.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = filenames[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_data(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3201, 10)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb4258d8d10>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb4258b9c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.Open.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(1000, 64) dtype=float32_ref>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_get.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = exists(embedding_col_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not flag:\n",
    "    data = []\n",
    "    for filename in filenames:\n",
    "        df = get_data(filename)\n",
    "        binning_sentence = data_normalize(df, 'Close')\n",
    "        inds = list(binning_data(binning_sentence).flat)\n",
    "        data.append(inds)\n",
    "    with open(embedding_col_path, 'w') as f:\n",
    "        f.write(json.dumps(data))\n",
    "else:\n",
    "    #Now read the file back into a Python list object\n",
    "    with open(embedding_col_path, 'r') as f:\n",
    "        data = json.loads(f.read())  \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7163"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "346"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 10, 12, 12, 19, 12, 157, 187, 70, 58]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_label(data, len_seq = 10):\n",
    "    y = []\n",
    "    seq_x = []\n",
    "    for i in range(0, len(data), len_seq):\n",
    "        if i-10>=0:\n",
    "            list_data = data[i-10:i]\n",
    "            next_data = data[i+1]\n",
    "            if next_data > data[i]:\n",
    "                label = 1\n",
    "            else:\n",
    "                label = 0\n",
    "            y.append(label)\n",
    "            seq_x.append(list_data)\n",
    "    return seq_x, y\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "346"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "seq_x = []\n",
    "for i in range(len(data)):\n",
    "    one_x, one_y = get_label(data[i])\n",
    "    y += one_y\n",
    "    seq_x += one_x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243542"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seq_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243542"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seq_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[272, 266, 249, 213, 272, 261, 266, 239, 269, 268]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_x[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_y = {}\n",
    "for item in y:\n",
    "    if item ==0:\n",
    "        if item not in hist_y:\n",
    "            hist_y[item] = 0\n",
    "        else:\n",
    "            hist_y[item] +=1\n",
    "    if item ==1:\n",
    "        if item not in hist_y:\n",
    "            hist_y[item] = 0\n",
    "        else:\n",
    "            hist_y[item] +=1            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_graph():\n",
    "    if 'sess' in globals() and sess:\n",
    "        sess.close()\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "def build_graph(\n",
    "    state_size = 64,\n",
    "    batch_size = 256,\n",
    "    num_classes = 2):\n",
    "\n",
    "    reset_graph()\n",
    "\n",
    "    # Placeholders\n",
    "    x = tf.placeholder(tf.int32, [batch_size, None]) # [batch_size, num_steps]\n",
    "    seqlen = tf.placeholder(tf.int32, [batch_size])\n",
    "    y = tf.placeholder(tf.int32, [batch_size])\n",
    "    keep_prob = tf.constant(1.0)\n",
    "\n",
    "    # Embedding layer\n",
    "#    embeddings = tf.get_variable('embedding_matrix', [vocab_size, state_size])\n",
    "    \n",
    "    embedding_save_path = os.path.join(pathModel, \"data.npy\")\n",
    "    data_get = np.load(embedding_save_path)\n",
    "    embeddings = tf.Variable(data_get)\n",
    "    rnn_inputs = tf.nn.embedding_lookup(embeddings, x)\n",
    "    # RNN\n",
    "    cell = tf.nn.rnn_cell.GRUCell(state_size)\n",
    "    init_state = tf.get_variable('init_state', [1, state_size],\n",
    "                                 initializer=tf.constant_initializer(0.0))\n",
    "    init_state = tf.tile(init_state, [batch_size, 1])\n",
    "    rnn_outputs, final_state = tf.nn.dynamic_rnn(cell, rnn_inputs, sequence_length=seqlen,\n",
    "                                                 initial_state=init_state)\n",
    "\n",
    "    # Add dropout, as the model otherwise quickly overfits\n",
    "    rnn_outputs = tf.nn.dropout(rnn_outputs, keep_prob)\n",
    "\n",
    "    \"\"\"\n",
    "    Obtain the last relevant output. The best approach in the future will be to use:\n",
    "\n",
    "        last_rnn_output = tf.gather_nd(rnn_outputs, tf.pack([tf.range(batch_size), seqlen-1], axis=1))\n",
    "\n",
    "    which is the Tensorflow equivalent of numpy's rnn_outputs[range(30), seqlen-1, :], but the\n",
    "    gradient for this op has not been implemented as of this writing.\n",
    "\n",
    "    The below solution works, but throws a UserWarning re: the gradient.\n",
    "    \"\"\"\n",
    "    idx = tf.range(batch_size)*tf.shape(rnn_outputs)[1] + (seqlen - 1)\n",
    "    last_rnn_output = tf.gather(tf.reshape(rnn_outputs, [-1, state_size]), idx)\n",
    "\n",
    "    # Softmax layer\n",
    "    with tf.variable_scope('softmax'):\n",
    "        W = tf.get_variable('W', [state_size, num_classes])\n",
    "        b = tf.get_variable('b', [num_classes], initializer=tf.constant_initializer(0.0))\n",
    "    logits = tf.matmul(last_rnn_output, W) + b\n",
    "    \n",
    "    preds = tf.nn.softmax(logits)\n",
    "    correct = tf.equal(tf.cast(tf.argmax(preds,1),tf.int32), y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits = logits, labels = y ))\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "\n",
    "    return {\n",
    "        'x': x,\n",
    "        'seqlen': seqlen,\n",
    "        'y': y,\n",
    "        'dropout': keep_prob,\n",
    "        'rnn_out':rnn_outputs,\n",
    "        'last_rnn_output':last_rnn_output,\n",
    "        'loss': loss,\n",
    "        'ts': train_step,\n",
    "        'preds': preds,\n",
    "        'accuracy': accuracy\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = build_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Merge/MergeSummary:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.summary.scalar(\"loss\", g[\"loss\"])\n",
    "\n",
    "merged_summary_op = tf.summary.merge_all()\n",
    "if merged_summary_op == None:\n",
    "    merged_summary_op = tf.summary.merge_all()\n",
    "merged_summary_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_DIR = '/tmp/testing/stock_prediction_1'\n",
    "#tensorboard --logdir=/tmp/testing/example_2_2\n",
    "summary_writer = tf.summary.FileWriter(LOG_DIR, graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_start = int(len(seq_x)*0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "#import keras.backend.tensorflow_backend as KTF\n",
    "try:\n",
    "    sess = tf.Session()\n",
    "except:\n",
    "    sess = tf.Session()\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "YY = np.array(y).reshape((len(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(243542,)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 1])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed_dict[g[\"y\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enc_label = OneHotEncoder()\n",
    "# YY = enc_label.fit(YY).transform(YY)\n",
    "# YY = YY.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'Placeholder_1' with dtype int32 and shape [256]\n\t [[Node: Placeholder_1 = Placeholder[dtype=DT_INT32, shape=[256], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op u'Placeholder_1', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-187-e2f4ecda7354>\", line 1, in <module>\n    g = build_graph()\n  File \"<ipython-input-186-b8b66fb78b04>\", line 15, in build_graph\n    seqlen = tf.placeholder(tf.int32, [batch_size])\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.py\", line 1599, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 3091, in _placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder_1' with dtype int32 and shape [256]\n\t [[Node: Placeholder_1 = Placeholder[dtype=DT_INT32, shape=[256], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-203-956578615994>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_1' with dtype int32 and shape [256]\n\t [[Node: Placeholder_1 = Placeholder[dtype=DT_INT32, shape=[256], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op u'Placeholder_1', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-187-e2f4ecda7354>\", line 1, in <module>\n    g = build_graph()\n  File \"<ipython-input-186-b8b66fb78b04>\", line 15, in build_graph\n    seqlen = tf.placeholder(tf.int32, [batch_size])\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.py\", line 1599, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 3091, in _placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder_1' with dtype int32 and shape [256]\n\t [[Node: Placeholder_1 = Placeholder[dtype=DT_INT32, shape=[256], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "result = sess.run(g[\"ts\"], feed_dict = feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new training, 11 29, 2017\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'Placeholder_1' with dtype int32 and shape [256]\n\t [[Node: Placeholder_1 = Placeholder[dtype=DT_INT32, shape=[256], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op u'Placeholder_1', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-187-e2f4ecda7354>\", line 1, in <module>\n    g = build_graph()\n  File \"<ipython-input-186-b8b66fb78b04>\", line 15, in build_graph\n    seqlen = tf.placeholder(tf.int32, [batch_size])\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.py\", line 1599, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 3091, in _placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder_1' with dtype int32 and shape [256]\n\t [[Node: Placeholder_1 = Placeholder[dtype=DT_INT32, shape=[256], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-196-916d09383791>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m                  }\n\u001b[1;32m     13\u001b[0m     _, c, pre, summary = sess.run([g[\"ts\"], g[\"loss\"], g[\"accuracy\"], merged_summary_op],\n\u001b[0;32m---> 14\u001b[0;31m                                   feed_dict= feed_dict)\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0msummary_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_1' with dtype int32 and shape [256]\n\t [[Node: Placeholder_1 = Placeholder[dtype=DT_INT32, shape=[256], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op u'Placeholder_1', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-187-e2f4ecda7354>\", line 1, in <module>\n    g = build_graph()\n  File \"<ipython-input-186-b8b66fb78b04>\", line 15, in build_graph\n    seqlen = tf.placeholder(tf.int32, [batch_size])\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.py\", line 1599, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 3091, in _placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder_1' with dtype int32 and shape [256]\n\t [[Node: Placeholder_1 = Placeholder[dtype=DT_INT32, shape=[256], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "epoch = 0\n",
    "batch = 256\n",
    "\n",
    "print (\"new training, 11 29, 2017\")\n",
    "num_epoch = len(seq_x)*0.85/ batch\n",
    "\n",
    "while epoch<num_epoch-1:\n",
    "    start = epoch*batch\n",
    "    end = (epoch + 1)*batch\n",
    "    feed_dict = {g['x']:seq_x[start:end], \n",
    "                 g['y']:YY[start:end]\n",
    "                 }\n",
    "    _, c, pre, summary = sess.run([g[\"ts\"], g[\"loss\"], g[\"accuracy\"], merged_summary_op],\n",
    "                                  feed_dict= feed_dict)\n",
    "    summary_writer.add_summary(summary, epoch)\n",
    "\n",
    "    feed_dict = {g['x']:seq_x[test_data_start:], \n",
    "                 g['y']:YY[test_data_start:]\n",
    "                 }\n",
    "    test_temp_accuracy = sess.run(g[\"accuracy\"], feed_dict= feed_dict)\n",
    "    loss_list.append(test_temp_accuracy)\n",
    "    if epoch%100 ==0:\n",
    "        print('Accuarcy = ' + str(test_temp_accuracy))\n",
    "        print('accuracy training is = ' + str(test_temp_accuracy))\n",
    "    epoch +=1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Gather:0' shape=(256, 64) dtype=float32>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g[\"last_rnn_output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     \"\"\"\n",
    "#     Obtain the last relevant output. The best approach in the future will be to use:\n",
    "\n",
    "#         last_rnn_output = tf.gather_nd(rnn_outputs, tf.pack([tf.range(batch_size), seqlen-1], axis=1))\n",
    "\n",
    "#     which is the Tensorflow equivalent of numpy's rnn_outputs[range(30), seqlen-1, :], but the\n",
    "#     gradient for this op has not been implemented as of this writing.\n",
    "\n",
    "#     The below solution works, but throws a UserWarning re: the gradient.\n",
    "#     \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = tf.range(batch_size)*tf.shape(rnn_outputs)[1] + (seqlen - 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_rnn_output = tf.gather(tf.reshape(rnn_outputs, [-1, state_size]), idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_size = 10\n",
    "batch_size = 100\n",
    "lstm_cell = tf.contrib.rnn.BasicLSTMCell(rnn_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = lstm_cell.zero_state(batch_size, tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "batch_size = 256\n",
    "embedding_size = 64\n",
    "generations = 50000\n",
    "print_loss_every = 500\n",
    "num_embedding = 1000\n",
    "num_sampled = int(batch_size/2)    # Number of negative examples to sample.\n",
    "window_size = 8       # How many words to consider left and right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_examples = [1,20,30,149,293]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data randomly (N words behind, target, N words ahead)\n",
    "def generate_batch_data(sentences, batch_size, window_size, method='skip_gram'):\n",
    "    # Fill up data batch\n",
    "    batch_data = []\n",
    "    label_data = []\n",
    "    while len(batch_data) < batch_size:\n",
    "        # select random sentence to start\n",
    "        idx = np.random.choice(len(sentences),1)\n",
    "        rand_sentence = sentences[idx[0]]\n",
    "        # Generate consecutive windows to look at\n",
    "        window_sequences = [rand_sentence[max((ix-window_size),0):(ix+window_size+1)] for ix, x in enumerate(rand_sentence)]\n",
    "        # Denote which element of each window is the center word of interest\n",
    "        label_indices = [ix if ix<window_size else window_size for ix,x in enumerate(window_sequences)]\n",
    "        \n",
    "        # Pull out center word of interest for each window and create a tuple for each window\n",
    "        if method=='skip_gram':\n",
    "            batch_and_labels = [(x[y], x[:y] + x[(y+1):]) for x,y in zip(window_sequences, label_indices)]\n",
    "            # Make it in to a big list of tuples (target word, surrounding word)\n",
    "            tuple_data = [(x, y_) for x,y in batch_and_labels for y_ in y]\n",
    "        elif method=='cbow':\n",
    "            batch_and_labels = [(x[:y] + x[(y+1):], x[y]) for x,y in zip(window_sequences, label_indices)]\n",
    "            # Make it in to a big list of tuples (target word, surrounding word)\n",
    "            tuple_data = [(x_, y) for x,y in batch_and_labels for x_ in x]\n",
    "        else:\n",
    "            raise ValueError('Method {} not implemented yet.'.format(method))\n",
    "            \n",
    "        # extract batch and labels\n",
    "        batch, labels = [list(x) for x in zip(*tuple_data)]\n",
    "        batch_data.extend(batch[:batch_size])\n",
    "        label_data.extend(labels[:batch_size])\n",
    "    # Trim batch and label at the end\n",
    "    batch_data = batch_data[:batch_size]\n",
    "    label_data = label_data[:batch_size]\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    batch_data = np.array(batch_data)\n",
    "    label_data = np.transpose(np.array([label_data]).astype(int))\n",
    "    \n",
    "    return(batch_data, label_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Embeddings:\n",
    "embeddings = tf.Variable(tf.random_uniform([num_embedding, embedding_size], -1.0, 1.0), name = \"product_vec\")\n",
    "\n",
    "# NCE loss parameters\n",
    "nce_weights = tf.Variable(tf.truncated_normal([num_embedding, embedding_size],\n",
    "                                               stddev=1.0 / np.sqrt(embedding_size)))\n",
    "nce_biases = tf.Variable(tf.zeros([num_embedding]))\n",
    "\n",
    "# Create data/target placeholders\n",
    "x_inputs = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "y_target = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
    "valid_dataset = tf.constant(valid_examples, dtype=tf.int32)\n",
    "\n",
    "# Lookup the word embedding:\n",
    "embed = tf.nn.embedding_lookup(embeddings, x_inputs)\n",
    "\n",
    "# Get loss from prediction\n",
    "loss_get = tf.nn.nce_loss(weights=nce_weights,            # Tensor of shape(50000, 128)\n",
    "                          biases=nce_biases,              # vector of zeros; len(128)\n",
    "                          labels=y_target,            # labels == context words enums\n",
    "                          inputs=embed,                   # Tensor of shape(128, 128)\n",
    "                          num_sampled=num_sampled,        # 64: randomly chosen negative (rare) words\n",
    "                          num_classes=num_embedding)   # 50000: by construction\n",
    "loss = tf.reduce_mean(loss_get)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1.0).minimize(loss)\n",
    "\n",
    "tf.summary.scalar(\"loss\", loss)\n",
    "\n",
    "merged_summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine similarity between words\n",
    "norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keep_dims=True))\n",
    "normalized_embeddings = embeddings / norm\n",
    "valid_embeddings = tf.nn.embedding_lookup(normalized_embeddings, valid_dataset)\n",
    "similarity = tf.matmul(valid_embeddings, normalized_embeddings, transpose_b=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "\n",
    "\n",
    "try:\n",
    "    sess = tf.Session(config=config)\n",
    "except:\n",
    "    sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add variable initializer.\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 500 : 3.09951066971\n",
      "Loss at step 1000 : 2.23416495323\n",
      "Loss at step 1500 : 2.69590902328\n"
     ]
    }
   ],
   "source": [
    "LOG_DIR = '/tmp/testing/stock2vec_1'\n",
    "#tensorboard --logdir=/tmp/testing/example_2_2\n",
    "summary_writer = tf.summary.FileWriter(LOG_DIR, graph=tf.get_default_graph())\n",
    "print_valid_every = 100\n",
    "# Run the skip gram model.\n",
    "valid_words = [1,23,10,300]\n",
    "loss_vec = []\n",
    "loss_x_vec = []\n",
    "for i in range(generations):\n",
    "    batch_inputs, batch_labels = generate_batch_data(data, batch_size, window_size)\n",
    "    feed_dict = {x_inputs : batch_inputs, y_target : batch_labels}\n",
    "\n",
    "    # Run the train step\n",
    "    _, summary = sess.run([optimizer, merged_summary_op], feed_dict=feed_dict)\n",
    "    \n",
    "    summary_writer.add_summary(summary, i)\n",
    "\n",
    "    # Return the loss\n",
    "    if (i+1) % print_loss_every == 0:\n",
    "        loss_val = sess.run(loss, feed_dict=feed_dict)\n",
    "        loss_vec.append(loss_val)\n",
    "        loss_x_vec.append(i+1)\n",
    "        print(\"Loss at step {} : {}\".format(i+1, loss_val))\n",
    "      \n",
    "    # Validation: Print some random words and top 5 related words\n",
    "#     if (i+1) % print_valid_every == 0:\n",
    "#         sim = sess.run(similarity, feed_dict=feed_dict)\n",
    "#         for j in range(len(valid_words)):\n",
    "#             valid_word = name_dict[word_dictionary_rev[valid_examples[0]]] #word_dictionary_rev[valid_examples[j]]\n",
    "#             top_k = 5 # number of nearest neighbors\n",
    "#             nearest = (-sim[j, :]).argsort()[1:top_k+1]\n",
    "#             #name_dict[word_dictionary_rev[valid_examples[0]]]\n",
    "#             log_str = \"Nearest to {}::\".format(valid_word)\n",
    "#             for k in range(top_k):\n",
    "#                 close_word = name_dict[word_dictionary_rev[valid_examples[k]]] #word_dictionary_rev[nearest[k]]\n",
    "#                 log_str = \"%s %s,\" % (log_str, close_word)\n",
    "#             print(log_str)\n",
    "#             print \"#################\"\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame() #creates a new dataframe that's empty\n",
    "new_df[\"index\"] = range(num_embedding)\n",
    "import csv\n",
    "new_df.to_csv(os.path.join(LOG_DIR, 'output2.tsv'), sep='\\t', quoting=csv.QUOTE_NONE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "# Create randomly initialized embedding weights which will be trained.\n",
    "\n",
    "# Format: tensorflow/tensorboard/plugins/projector/projector_config.proto\n",
    "config = projector.ProjectorConfig()\n",
    "\n",
    "# You can add multiple embeddings. Here we add only one.\n",
    "embedding = config.embeddings.add()\n",
    "embedding.tensor_name = 'product_vec'\n",
    "# Link this tensor to its metadata file (e.g. labels).\n",
    "embedding.metadata_path = os.path.join(LOG_DIR, 'output2.tsv')\n",
    "\n",
    "# Use the same LOG_DIR where you stored your checkpoint.\n",
    "summary_writer = tf.summary.FileWriter(LOG_DIR)\n",
    "\n",
    "# The next line writes a projector_config.pbtxt in the LOG_DIR. TensorBoard will\n",
    "# read this file during startup.\n",
    "projector.visualize_embeddings(summary_writer, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/testing/stock2vec_1/model.ckpt-1000'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "saver.save(sess, os.path.join(LOG_DIR, \"model.ckpt\"), 1000)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
