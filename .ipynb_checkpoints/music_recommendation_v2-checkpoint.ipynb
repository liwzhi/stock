{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/notebooks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "members_path = data_path + '/members.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from gensim.models.keyedvectors import KeyedVectors\n",
    "#word_vectors = KeyedVectors.load_word2vec_format('/notebooks/GoogleNews-vectors-negative300.bin', binary=True)  # C binary format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>city</th>\n",
       "      <th>bd</th>\n",
       "      <th>gender</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>registration_init_time</th>\n",
       "      <th>expiration_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XQxgAYj3klVKjR3oxPPXYYFp4soD4TuBghkhMTD4oTw=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>20110820</td>\n",
       "      <td>20170920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UizsfmJb9mV54qE9hCYyU07Va97c0lCRLEQX3ae+ztM=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>20150628</td>\n",
       "      <td>20170622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D8nEhsIOBSoE6VthTaqDX8U6lqjJ7dLdr72mOyLya2A=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>20160411</td>\n",
       "      <td>20170712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mCuD+tZ1hERA/o5GPqk38e041J8ZsBaLcu7nGoIIvhI=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>20150906</td>\n",
       "      <td>20150907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>q4HRBfVSssAFS9iRfxWrohxuk9kCYMKjHOEagUMV6rQ=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>20170126</td>\n",
       "      <td>20170613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>zgPOEyUn5a/Fvuzb3m69ajzxjkbblVtObglW89FzLdo=</td>\n",
       "      <td>13</td>\n",
       "      <td>43</td>\n",
       "      <td>female</td>\n",
       "      <td>9</td>\n",
       "      <td>20120703</td>\n",
       "      <td>20171006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sw9AT8QoR4wWiNUqHZUH6g5ahzGUx4lo1g+Y3xE2f2M=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>20160326</td>\n",
       "      <td>20160329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pg6bT2XZkSP1TDBy4qn3HBPY/HffKQ/bg8WIISQYBSY=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>20160130</td>\n",
       "      <td>20170930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kfk1AdTNH2dNqF5LzIs4e0vwGPejw2jrnFjJlcYnEgk=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>20110111</td>\n",
       "      <td>20170930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tscijwx4dbEp0NXGl+iFtHJ8zrj+TkcMrduOQk9t+gE=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>20160217</td>\n",
       "      <td>20170613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  city  bd  gender  \\\n",
       "0  XQxgAYj3klVKjR3oxPPXYYFp4soD4TuBghkhMTD4oTw=     1   0     NaN   \n",
       "1  UizsfmJb9mV54qE9hCYyU07Va97c0lCRLEQX3ae+ztM=     1   0     NaN   \n",
       "2  D8nEhsIOBSoE6VthTaqDX8U6lqjJ7dLdr72mOyLya2A=     1   0     NaN   \n",
       "3  mCuD+tZ1hERA/o5GPqk38e041J8ZsBaLcu7nGoIIvhI=     1   0     NaN   \n",
       "4  q4HRBfVSssAFS9iRfxWrohxuk9kCYMKjHOEagUMV6rQ=     1   0     NaN   \n",
       "5  zgPOEyUn5a/Fvuzb3m69ajzxjkbblVtObglW89FzLdo=    13  43  female   \n",
       "6  Sw9AT8QoR4wWiNUqHZUH6g5ahzGUx4lo1g+Y3xE2f2M=     1   0     NaN   \n",
       "7  pg6bT2XZkSP1TDBy4qn3HBPY/HffKQ/bg8WIISQYBSY=     1   0     NaN   \n",
       "8  kfk1AdTNH2dNqF5LzIs4e0vwGPejw2jrnFjJlcYnEgk=     1   0     NaN   \n",
       "9  tscijwx4dbEp0NXGl+iFtHJ8zrj+TkcMrduOQk9t+gE=     1   0     NaN   \n",
       "\n",
       "   registered_via  registration_init_time  expiration_date  \n",
       "0               7                20110820         20170920  \n",
       "1               7                20150628         20170622  \n",
       "2               4                20160411         20170712  \n",
       "3               9                20150906         20150907  \n",
       "4               4                20170126         20170613  \n",
       "5               9                20120703         20171006  \n",
       "6               4                20160326         20160329  \n",
       "7               7                20160130         20170930  \n",
       "8               7                20110111         20170930  \n",
       "9               7                20160217         20170613  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "members = pd.read_csv(members_path)\n",
    "\n",
    "members.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_path = data_path + \"/sample_submission.csv\"\n",
    "submit = pd.read_csv(submit_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0     0.5\n",
       "1   1     0.5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/notebooks/\"\n",
    "path_data = \"/notebooks/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import pandas as pd\n",
    "#import gensim\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.contrib.learn.python.learn.preprocessing import text\n",
    "#from nltk.stem.snowball import SnowballStemmer\n",
    "import datetime\n",
    "\n",
    "from random import *\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import time\n",
    "import glob, os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import sys\n",
    "reload(sys)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_extra_path = path_data + \"song_extra_info.csv\"\n",
    "songs_extra_infor = pd.read_csv(songs_extra_path)\n",
    "\n",
    "songs_extra_infor.head(4)\n",
    "\n",
    "songs_path = path_data + \"songs.csv\"\n",
    "\n",
    "songs_infor = pd.read_csv(songs_path)\n",
    "\n",
    "songs_infor.head(4)\n",
    "\n",
    "train_path = path_data + \"train.csv\"\n",
    "train_data = pd.read_csv(train_path)\n",
    "\n",
    "\n",
    "train_data.head(4)\n",
    "\n",
    "test_path = path_data + \"test.csv\"\n",
    "test_data = pd.read_csv(test_path)\n",
    "\n",
    "\n",
    "test_data.head(3)\n",
    "\n",
    "\n",
    "def merge_user_song_train(train_data, members, songs_extra_infor):\n",
    "    user_train_merge = pd.merge(train_data, members, on='msno', how = \"left\")\n",
    "    song_user_train = pd.merge(user_train_merge, songs_extra_infor, on='song_id', how = \"left\")\n",
    "    return song_user_train\n",
    "\n",
    "song_user_train = merge_user_song_train(train_data, members, songs_extra_infor)\n",
    "\n",
    "song_user_test = merge_user_song_train(test_data, members, songs_extra_infor)\n",
    "\n",
    "\n",
    "assert(song_user_train.shape[0] ==train_data.shape[0])\n",
    "assert(song_user_test.shape[0] ==test_data.shape[0])\n",
    "assert(song_user_test.shape[1] == song_user_train.shape[1])\n",
    "\n",
    "\n",
    "# In[19]:\n",
    "\n",
    "song_user_test.shape[1]\n",
    "\n",
    "\n",
    "# In[20]:\n",
    "\n",
    "song_user_train.shape[1]\n",
    "\n",
    "\n",
    "# In[21]:\n",
    "\n",
    "diff_col_1 = []\n",
    "same_col_1 = []\n",
    "for item in list(song_user_test.columns.values):\n",
    "    if item not in list(song_user_train.columns.values):\n",
    "        diff_col_1.append(item)\n",
    "    else:\n",
    "        same_col_1.append(item)\n",
    "\n",
    "\n",
    "# In[22]:\n",
    "\n",
    "diff_col_1\n",
    "\n",
    "\n",
    "# In[23]:\n",
    "\n",
    "diff_col = []\n",
    "same_col = []\n",
    "for item in list(song_user_train.columns.values):\n",
    "    if item not in list(song_user_test.columns.values):\n",
    "        diff_col.append(item)\n",
    "    else:\n",
    "        same_col.append(item)\n",
    "\n",
    "\n",
    "\n",
    "# In[24]:\n",
    "\n",
    "same_col\n",
    "\n",
    "categorical_columns = same_col\n",
    "\n",
    "data_categorial = song_user_train[categorical_columns]\n",
    "data_categorial.fillna(\"\", inplace=True)\n",
    "\n",
    "# # for test data\n",
    "data_test_categorial = song_user_test[categorical_columns]\n",
    "data_test_categorial.fillna(\"\", inplace=True)\n",
    "\n",
    "data_categorial.head(5)\n",
    "\n",
    "\n",
    "def label_encoder(data, columns, embedding_size):\n",
    "    list_transfomer = {}\n",
    "    size_col = {}\n",
    "    embedding_col = {}\n",
    "    transformer_value = {}\n",
    "    for col in columns:\n",
    "        col_transformer = LabelEncoder()\n",
    "        col_transformer.fit(data[col].values)\n",
    "        list_transfomer[col] = col_transformer\n",
    "        size_col[col] = len(np.unique(data[col]))\n",
    "        embedding_col[col] = np.random.rand(len(np.unique(data[col])), embedding_size)\n",
    "        transformer_value[col] = col_transformer.transform(data[col].values)\n",
    "    return list_transfomer, size_col, embedding_col, transformer_value\n",
    "\n",
    "\n",
    "def label_encoder_exist(data, columns, embedding_size, list_transfomer):\n",
    "    size_col = {}\n",
    "    embedding_col = {}\n",
    "    transformer_value = {}\n",
    "    for col in columns:\n",
    "        col_transformer = list_transfomer[col]\n",
    "        size_col[col] = len(np.unique(data[col]))\n",
    "        embedding_col[col] = np.random.rand(len(np.unique(data[col])), embedding_size)\n",
    "        transformer_value[col] = col_transformer.transform(data[col].values)\n",
    "    return list_transfomer, size_col, embedding_col, transformer_value\n",
    "\n",
    "\n",
    "def exists(path):\n",
    "    \"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\n",
    "    try:\n",
    "        st = os.stat(path)\n",
    "    except os.error:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "# In[34]:\n",
    "\n",
    "pathModel = os.getcwd()  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>song_id</th>\n",
       "      <th>source_system_tab</th>\n",
       "      <th>source_screen_name</th>\n",
       "      <th>source_type</th>\n",
       "      <th>target</th>\n",
       "      <th>city</th>\n",
       "      <th>bd</th>\n",
       "      <th>gender</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>registration_init_time</th>\n",
       "      <th>expiration_date</th>\n",
       "      <th>name</th>\n",
       "      <th>isrc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FGtllVqz18RPiwJj/edr2gV78zirAiY/9SmYvia+kCg=</td>\n",
       "      <td>BBzumQNXUHKdEBOB7mAJuzok+IJA1c2Ryg/yzTF6tik=</td>\n",
       "      <td>explore</td>\n",
       "      <td>Explore</td>\n",
       "      <td>online-playlist</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>20120102</td>\n",
       "      <td>20171005</td>\n",
       "      <td>Good Grief</td>\n",
       "      <td>GBUM71602854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Xumu+NIjS6QYVxDS4/t3SawvJ7viT9hPKXmf0RtLNx8=</td>\n",
       "      <td>bhp/MpSNoqoxOIB+/l8WPqu6jldth4DIpCm3ayXnJqM=</td>\n",
       "      <td>my library</td>\n",
       "      <td>Local playlist more</td>\n",
       "      <td>local-playlist</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>female</td>\n",
       "      <td>9</td>\n",
       "      <td>20110525</td>\n",
       "      <td>20170911</td>\n",
       "      <td>Lords of Cardboard</td>\n",
       "      <td>US3C69910183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Xumu+NIjS6QYVxDS4/t3SawvJ7viT9hPKXmf0RtLNx8=</td>\n",
       "      <td>JNWfrrC7zNN7BdMpsISKa4Mw+xVJYNnxXh3/Epw7QgY=</td>\n",
       "      <td>my library</td>\n",
       "      <td>Local playlist more</td>\n",
       "      <td>local-playlist</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>female</td>\n",
       "      <td>9</td>\n",
       "      <td>20110525</td>\n",
       "      <td>20170911</td>\n",
       "      <td>Hip Hop Is Dead(Album Version (Edited))</td>\n",
       "      <td>USUM70618761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Xumu+NIjS6QYVxDS4/t3SawvJ7viT9hPKXmf0RtLNx8=</td>\n",
       "      <td>2A87tzfnJTSWqD7gIZHisolhe4DMdzkbd6LzO1KHjNs=</td>\n",
       "      <td>my library</td>\n",
       "      <td>Local playlist more</td>\n",
       "      <td>local-playlist</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>female</td>\n",
       "      <td>9</td>\n",
       "      <td>20110525</td>\n",
       "      <td>20170911</td>\n",
       "      <td>Disco Africa</td>\n",
       "      <td>GBUQH1000063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  \\\n",
       "0  FGtllVqz18RPiwJj/edr2gV78zirAiY/9SmYvia+kCg=   \n",
       "1  Xumu+NIjS6QYVxDS4/t3SawvJ7viT9hPKXmf0RtLNx8=   \n",
       "2  Xumu+NIjS6QYVxDS4/t3SawvJ7viT9hPKXmf0RtLNx8=   \n",
       "3  Xumu+NIjS6QYVxDS4/t3SawvJ7viT9hPKXmf0RtLNx8=   \n",
       "\n",
       "                                        song_id source_system_tab  \\\n",
       "0  BBzumQNXUHKdEBOB7mAJuzok+IJA1c2Ryg/yzTF6tik=           explore   \n",
       "1  bhp/MpSNoqoxOIB+/l8WPqu6jldth4DIpCm3ayXnJqM=        my library   \n",
       "2  JNWfrrC7zNN7BdMpsISKa4Mw+xVJYNnxXh3/Epw7QgY=        my library   \n",
       "3  2A87tzfnJTSWqD7gIZHisolhe4DMdzkbd6LzO1KHjNs=        my library   \n",
       "\n",
       "    source_screen_name      source_type  target  city  bd  gender  \\\n",
       "0              Explore  online-playlist       1     1   0     NaN   \n",
       "1  Local playlist more   local-playlist       1    13  24  female   \n",
       "2  Local playlist more   local-playlist       1    13  24  female   \n",
       "3  Local playlist more   local-playlist       1    13  24  female   \n",
       "\n",
       "   registered_via  registration_init_time  expiration_date  \\\n",
       "0               7                20120102         20171005   \n",
       "1               9                20110525         20170911   \n",
       "2               9                20110525         20170911   \n",
       "3               9                20110525         20170911   \n",
       "\n",
       "                                      name          isrc  \n",
       "0                               Good Grief  GBUM71602854  \n",
       "1                       Lords of Cardboard  US3C69910183  \n",
       "2  Hip Hop Is Dead(Album Version (Edited))  USUM70618761  \n",
       "3                             Disco Africa  GBUQH1000063  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_user_train.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>msno</th>\n",
       "      <th>song_id</th>\n",
       "      <th>source_system_tab</th>\n",
       "      <th>source_screen_name</th>\n",
       "      <th>source_type</th>\n",
       "      <th>city</th>\n",
       "      <th>bd</th>\n",
       "      <th>gender</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>registration_init_time</th>\n",
       "      <th>expiration_date</th>\n",
       "      <th>name</th>\n",
       "      <th>isrc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>V8ruy7SGk7tDm3zA51DPpn6qutt+vmKMBKa21dp54uM=</td>\n",
       "      <td>WmHKgKMlp1lQMecNdNvDMkvIycZYHnFwDT72I5sIssc=</td>\n",
       "      <td>my library</td>\n",
       "      <td>Local playlist more</td>\n",
       "      <td>local-library</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>20160219</td>\n",
       "      <td>20170918</td>\n",
       "      <td>愛其實很殘忍</td>\n",
       "      <td>TWUM71400047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>V8ruy7SGk7tDm3zA51DPpn6qutt+vmKMBKa21dp54uM=</td>\n",
       "      <td>y/rsZ9DC7FwK5F2PK2D5mj+aOBUJAjuu3dZ14NgE0vM=</td>\n",
       "      <td>my library</td>\n",
       "      <td>Local playlist more</td>\n",
       "      <td>local-library</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>20160219</td>\n",
       "      <td>20170918</td>\n",
       "      <td>她說</td>\n",
       "      <td>TWB671005201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>/uQAlrAkaczV+nWCd2sPF2ekvXPRipV7q0l+gbLuxjw=</td>\n",
       "      <td>8eZLFOdGVdXBSqoAv5nsLigeH2BvKXzTQYtUM53I0k4=</td>\n",
       "      <td>discover</td>\n",
       "      <td>NaN</td>\n",
       "      <td>song-based-playlist</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>20161117</td>\n",
       "      <td>20161124</td>\n",
       "      <td>subarashiki nichijo</td>\n",
       "      <td>JPWP01070260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1a6oo/iXKatxQx4eS9zTVD+KlSVaAFbTIqVvwLC1Y0k=</td>\n",
       "      <td>ztCf8thYsS4YN3GcIL/bvoxLm/T5mYBVKOO4C9NiVfQ=</td>\n",
       "      <td>radio</td>\n",
       "      <td>Radio</td>\n",
       "      <td>radio</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>male</td>\n",
       "      <td>9</td>\n",
       "      <td>20070725</td>\n",
       "      <td>20170430</td>\n",
       "      <td>Hold Me| Thrill Me| Kiss Me| Kill Me</td>\n",
       "      <td>GBAAN0201228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                          msno  \\\n",
       "0   0  V8ruy7SGk7tDm3zA51DPpn6qutt+vmKMBKa21dp54uM=   \n",
       "1   1  V8ruy7SGk7tDm3zA51DPpn6qutt+vmKMBKa21dp54uM=   \n",
       "2   2  /uQAlrAkaczV+nWCd2sPF2ekvXPRipV7q0l+gbLuxjw=   \n",
       "3   3  1a6oo/iXKatxQx4eS9zTVD+KlSVaAFbTIqVvwLC1Y0k=   \n",
       "\n",
       "                                        song_id source_system_tab  \\\n",
       "0  WmHKgKMlp1lQMecNdNvDMkvIycZYHnFwDT72I5sIssc=        my library   \n",
       "1  y/rsZ9DC7FwK5F2PK2D5mj+aOBUJAjuu3dZ14NgE0vM=        my library   \n",
       "2  8eZLFOdGVdXBSqoAv5nsLigeH2BvKXzTQYtUM53I0k4=          discover   \n",
       "3  ztCf8thYsS4YN3GcIL/bvoxLm/T5mYBVKOO4C9NiVfQ=             radio   \n",
       "\n",
       "    source_screen_name          source_type  city  bd gender  registered_via  \\\n",
       "0  Local playlist more        local-library     1   0    NaN               7   \n",
       "1  Local playlist more        local-library     1   0    NaN               7   \n",
       "2                  NaN  song-based-playlist     1   0    NaN               4   \n",
       "3                Radio                radio     3  30   male               9   \n",
       "\n",
       "   registration_init_time  expiration_date  \\\n",
       "0                20160219         20170918   \n",
       "1                20160219         20170918   \n",
       "2                20161117         20161124   \n",
       "3                20070725         20170430   \n",
       "\n",
       "                                   name          isrc  \n",
       "0                                ������������������  TWUM71400047  \n",
       "1                                    ������  TWB671005201  \n",
       "2                   subarashiki nichijo  JPWP01070260  \n",
       "3  Hold Me| Thrill Me| Kiss Me| Kill Me  GBAAN0201228  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_user_test.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pathModel = os.getcwd()  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['msno',\n",
       " 'song_id',\n",
       " 'source_system_tab',\n",
       " 'source_screen_name',\n",
       " 'source_type',\n",
       " 'city',\n",
       " 'bd',\n",
       " 'gender',\n",
       " 'registered_via',\n",
       " 'registration_init_time',\n",
       " 'expiration_date',\n",
       " 'name',\n",
       " 'isrc']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_pickle(data_path):\n",
    "    with open(data_path, 'rb') as handle:\n",
    "        data_get = pickle.load(handle)\n",
    "    return data_get\n",
    "\n",
    "def save_picle(data_path, data):\n",
    "    with open(data_path, 'wb') as handle:\n",
    "        pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "pathModel = os.getcwd()  #\n",
    "embedding_col_path = os.path.join(pathModel, \"embedding_col.pickle\")\n",
    "transform_list_value_path = os.path.join(pathModel, \"transform_list_value.pickle\")\n",
    "list_transformer_path = os.path.join(pathModel, \"list_transformer.pickle\")\n",
    "size_col_path = os.path.join(pathModel, \"size_col.pickle\")\n",
    "\n",
    "embedding_col_path\n",
    "flag = exists(embedding_col_path)\n",
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns.remove('msno')\n",
    "categorical_columns.remove(\"song_id\")\n",
    "categorical_columns.remove(\"isrc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not flag:\n",
    "    list_transformer, size_col, embedding_col, transformer_value = label_encoder(data_categorial, categorical_columns, 8)\n",
    "    save_picle(embedding_col_path, embedding_col )\n",
    "    save_picle(transform_list_value_path, transformer_value )\n",
    "    save_picle(list_transformer_path, list_transformer )\n",
    "    save_picle(size_col_path, size_col )\n",
    "else:\n",
    "    list_transformer = load_pickle(list_transformer_path)\n",
    "    size_col = load_pickle(size_col_path)\n",
    "    transformer_value = load_pickle(transform_list_value_path)\n",
    "    embedding_col = load_pickle(embedding_col_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_user_test = merge_user_song_train(test_data, members, songs_extra_infor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_transformer_test_path = os.path.join(pathModel, \"list_transformer_test_path.pickle\")\n",
    "transform_list_value__test_path = os.path.join(pathModel, \"transform_list_value__test_path.pickle\")\n",
    "embedding_col_test_path = os.path.join(pathModel, \"embedding_col_test_path.pickle\")\n",
    "size_col_test_path = os.path.join(pathModel, \"size_col_test_path.pickle\")\n",
    "\n",
    "flag = exists(size_col_test_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>song_id</th>\n",
       "      <th>source_system_tab</th>\n",
       "      <th>source_screen_name</th>\n",
       "      <th>source_type</th>\n",
       "      <th>city</th>\n",
       "      <th>bd</th>\n",
       "      <th>gender</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>registration_init_time</th>\n",
       "      <th>expiration_date</th>\n",
       "      <th>name</th>\n",
       "      <th>isrc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V8ruy7SGk7tDm3zA51DPpn6qutt+vmKMBKa21dp54uM=</td>\n",
       "      <td>WmHKgKMlp1lQMecNdNvDMkvIycZYHnFwDT72I5sIssc=</td>\n",
       "      <td>my library</td>\n",
       "      <td>Local playlist more</td>\n",
       "      <td>local-library</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>20160219</td>\n",
       "      <td>20170918</td>\n",
       "      <td>愛其實很殘忍</td>\n",
       "      <td>TWUM71400047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>V8ruy7SGk7tDm3zA51DPpn6qutt+vmKMBKa21dp54uM=</td>\n",
       "      <td>y/rsZ9DC7FwK5F2PK2D5mj+aOBUJAjuu3dZ14NgE0vM=</td>\n",
       "      <td>my library</td>\n",
       "      <td>Local playlist more</td>\n",
       "      <td>local-library</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>20160219</td>\n",
       "      <td>20170918</td>\n",
       "      <td>她說</td>\n",
       "      <td>TWB671005201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/uQAlrAkaczV+nWCd2sPF2ekvXPRipV7q0l+gbLuxjw=</td>\n",
       "      <td>8eZLFOdGVdXBSqoAv5nsLigeH2BvKXzTQYtUM53I0k4=</td>\n",
       "      <td>discover</td>\n",
       "      <td></td>\n",
       "      <td>song-based-playlist</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>20161117</td>\n",
       "      <td>20161124</td>\n",
       "      <td>subarashiki nichijo</td>\n",
       "      <td>JPWP01070260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1a6oo/iXKatxQx4eS9zTVD+KlSVaAFbTIqVvwLC1Y0k=</td>\n",
       "      <td>ztCf8thYsS4YN3GcIL/bvoxLm/T5mYBVKOO4C9NiVfQ=</td>\n",
       "      <td>radio</td>\n",
       "      <td>Radio</td>\n",
       "      <td>radio</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>male</td>\n",
       "      <td>9</td>\n",
       "      <td>20070725</td>\n",
       "      <td>20170430</td>\n",
       "      <td>Hold Me| Thrill Me| Kiss Me| Kill Me</td>\n",
       "      <td>GBAAN0201228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  \\\n",
       "0  V8ruy7SGk7tDm3zA51DPpn6qutt+vmKMBKa21dp54uM=   \n",
       "1  V8ruy7SGk7tDm3zA51DPpn6qutt+vmKMBKa21dp54uM=   \n",
       "2  /uQAlrAkaczV+nWCd2sPF2ekvXPRipV7q0l+gbLuxjw=   \n",
       "3  1a6oo/iXKatxQx4eS9zTVD+KlSVaAFbTIqVvwLC1Y0k=   \n",
       "\n",
       "                                        song_id source_system_tab  \\\n",
       "0  WmHKgKMlp1lQMecNdNvDMkvIycZYHnFwDT72I5sIssc=        my library   \n",
       "1  y/rsZ9DC7FwK5F2PK2D5mj+aOBUJAjuu3dZ14NgE0vM=        my library   \n",
       "2  8eZLFOdGVdXBSqoAv5nsLigeH2BvKXzTQYtUM53I0k4=          discover   \n",
       "3  ztCf8thYsS4YN3GcIL/bvoxLm/T5mYBVKOO4C9NiVfQ=             radio   \n",
       "\n",
       "    source_screen_name          source_type  city  bd gender  registered_via  \\\n",
       "0  Local playlist more        local-library     1   0                      7   \n",
       "1  Local playlist more        local-library     1   0                      7   \n",
       "2                       song-based-playlist     1   0                      4   \n",
       "3                Radio                radio     3  30   male               9   \n",
       "\n",
       "   registration_init_time  expiration_date  \\\n",
       "0                20160219         20170918   \n",
       "1                20160219         20170918   \n",
       "2                20161117         20161124   \n",
       "3                20070725         20170430   \n",
       "\n",
       "                                   name          isrc  \n",
       "0                                ������������������  TWUM71400047  \n",
       "1                                    ������  TWB671005201  \n",
       "2                   subarashiki nichijo  JPWP01070260  \n",
       "3  Hold Me| Thrill Me| Kiss Me| Kill Me  GBAAN0201228  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test_categorial.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def label_test_transfer(data, columns, list_transfomer):\n",
    "    size_col = {}\n",
    "    embedding_col = {}\n",
    "    transformer_value = {}\n",
    "    for col in columns:\n",
    "        print \"######\"\n",
    "        print col\n",
    "        col_transformer = list_transfomer[col]\n",
    "        mask = -data[col].isin(list_transformer[col].classes_) # not in label encoder\n",
    "        mask_fill = data[col].isin(list_transformer[col].classes_) # in the label encoder\n",
    "        data[col][mask] = data[col][mask_fill][0] # fil it with the exist label        \n",
    "        size_col[col] = len(np.unique(data[col]))\n",
    "        transformer_value[col] = col_transformer.transform(data[col].values)\n",
    "    return list_transfomer, size_col, embedding_col, transformer_value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not flag:\n",
    "    list_transformer_test, size_col_test, embedding_col_test, transformer_value_test = label_test_transfer(data_test_categorial, categorical_columns, list_transformer)\n",
    "    save_picle(embedding_col_test_path, embedding_col_test )\n",
    "    save_picle(transform_list_value__test_path, transformer_value_test )\n",
    "    save_picle(list_transformer_test_path, list_transformer_test )\n",
    "    save_picle(size_col_test_path, size_col_test )\n",
    "else:\n",
    "    list_transformer = load_pickle(embedding_col_test_path)\n",
    "    transformer_value_test = load_pickle(transform_list_value__test_path)\n",
    "    list_transformer_test = load_pickle(list_transformer_test_path)\n",
    "    size_col_test = load_pickle(size_col_test_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['source_system_tab',\n",
       " 'source_screen_name',\n",
       " 'source_type',\n",
       " 'city',\n",
       " 'bd',\n",
       " 'gender',\n",
       " 'registered_via',\n",
       " 'registration_init_time',\n",
       " 'expiration_date',\n",
       " 'name']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def placeholder_lookup(cols, embedding_col):\n",
    "    placeholder_variable = {}\n",
    "    embedding_get = {}\n",
    "    value_lookup = {}\n",
    "    for col in cols:\n",
    "        print \"######\"\n",
    "        print col\n",
    "        x = tf.placeholder(tf.int64, [None], name=\"input_x_\" + \"col\")\n",
    "        embeddings = tf.Variable(embedding_col[col], name= \"embeddings_\" + col, dtype=tf.float32)\n",
    "\n",
    "        placeholder_variable[col] = x\n",
    "        embedding_get[col] = embeddings\n",
    "\n",
    "        value = tf.nn.embedding_lookup(embeddings, x, name= \"embeddings_lookup_\" + col)\n",
    "        value_lookup[col] = value\n",
    "    return placeholder_variable, embedding_get, value_lookup\n",
    "\n",
    "\n",
    "placeholder_variable, embedding_get, value_lookup = placeholder_lookup(categorical_columns, embedding_col)\n",
    "\n",
    "combine_tensor = value_lookup.values()\n",
    "\n",
    "categorial_tensor = tf.concat(combine_tensor, 1)\n",
    "\n",
    "learning_rate = 1e-3\n",
    "embedding_size = categorial_tensor.get_shape().as_list()[1]\n",
    "\n",
    "n_hidden = 250\n",
    "n_hidden_1 = 200\n",
    "n_class = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concat:0' shape=(?, 80) dtype=float32>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorial_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tf.Variable(tf.random_normal(shape=[n_hidden]), dtype=tf.float32)\n",
    "b_1 = tf.Variable(tf.random_normal(shape=[n_hidden_1]), dtype=tf.float32)\n",
    "b_2 = tf.Variable(tf.random_normal(shape=[n_class]), dtype=tf.float32)\n",
    "\n",
    "# Neural network weights\n",
    "try:\n",
    "    with tf.variable_scope(\"weight__get_6\"):\n",
    "        h = tf.get_variable(name='h0', shape=[embedding_size, n_hidden],\n",
    "                            initializer=tf.contrib.layers.xavier_initializer(), dtype=tf.float32)\n",
    "        h_1 = tf.get_variable(name='h1', shape=[n_hidden, n_hidden_1],\n",
    "                              initializer=tf.contrib.layers.xavier_initializer(), dtype=tf.float32)\n",
    "        W_out = tf.get_variable(name='out_w', shape=[n_hidden_1, n_class],\n",
    "                                initializer=tf.contrib.layers.xavier_initializer(), dtype=tf.float32)\n",
    "except:\n",
    "    with tf.variable_scope(\"weight__get_6\", reuse = True):\n",
    "        h = tf.get_variable(name='h0', shape=[embedding_size, n_hidden],\n",
    "                            initializer=tf.contrib.layers.xavier_initializer(), dtype=tf.float32)\n",
    "        h_1 = tf.get_variable(name='h1', shape=[n_hidden, n_hidden_1],\n",
    "                              initializer=tf.contrib.layers.xavier_initializer(), dtype=tf.float32)\n",
    "        W_out = tf.get_variable(name='out_w', shape=[n_hidden_1, n_class],\n",
    "                                initializer=tf.contrib.layers.xavier_initializer(), dtype=tf.float32)\n",
    "\n",
    "layer_1 = tf.nn.relu(tf.add(tf.matmul(categorial_tensor,h), b, name = \"layer_1\"))\n",
    "layer_2 = tf.nn.relu(tf.add(tf.matmul(layer_1, h_1), b_1, name = \"layer_2\"))\n",
    "\n",
    "W_out_final = tf.add(tf.matmul(layer_2, W_out), b_2, name = \"layer_3\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "song_user_train = shuffle(song_user_train)\n",
    "\n",
    "YY = song_user_train[\"target\"].reshape(( song_user_train[\"target\"].values.shape[0], 1))\n",
    "\n",
    "y = tf.placeholder(tf.float32, [None,2], name=\"input_y\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In[69]:\n",
    "\n",
    "enc_label = OneHotEncoder()\n",
    "YY = enc_label.fit(YY).transform(YY)\n",
    "YY = YY.toarray()\n",
    "\n",
    "\n",
    "# In[70]:\n",
    "\n",
    "YY[3:10]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out_layer = tf.nn.softmax(W_out_final, name = \"output_layer\")\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=out_layer, labels=y), name =\"cost\")\n",
    "\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(out_layer, 1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "\n",
    "try:\n",
    "    with tf.variable_scope(\"optimization_3\"):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "except:\n",
    "    with tf.variable_scope(\"optimization_3\", reuse=True):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "\n",
    "def make_path(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        os.makedirs(file_path)\n",
    "    return file_path\n",
    "\n",
    "\n",
    "# In[63]:\n",
    "\n",
    "logs_path = make_path(os.path.join(pathModel, 'music_logs_2'))\n",
    "\n",
    "\n",
    "# In[64]:\n",
    "\n",
    "placeholder_variable\n",
    "\n",
    "\n",
    "# In[65]:\n",
    "\n",
    "transformer_value\n",
    "\n",
    "\n",
    "# In[66]:\n",
    "\n",
    "batch = 128\n",
    "num_epoch = len(YY)/batch -1\n",
    "summary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
    "loss_list = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_path(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        os.makedirs(file_path)\n",
    "    return file_path\n",
    "\n",
    "logs_path = make_path(os.path.join(pathModel, 'music_logs_2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_train = optimizer.minimize(cost)\n",
    "# get the logs for the graph\n",
    "tf.summary.scalar(\"loss\", cost)\n",
    "\n",
    "\n",
    "epoch = 0\n",
    "count_train = int(transformer_value['bd'].shape[0]*0.9)\n",
    "num_epoch = transformer_value['bd'].shape[0]/batch -1\n",
    "\n",
    "import tensorflow as tf\n",
    "#import keras.backend.tensorflow_backend as KTF\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "try:\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.9)\n",
    "    sess = tf.Session(config=tf.ConfigProto(log_device_placement=True, gpu_options=gpu_options))\n",
    "except:\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.9)\n",
    "    sess = tf.Session(config=tf.ConfigProto(log_device_placement=True, gpu_options=gpu_options))\n",
    "\n",
    "transformer_value\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Merge/MergeSummary:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_summary_op = tf.summary.merge_all()\n",
    "if merged_summary_op == None:\n",
    "    merged_summary_op = tf.summary.merge_all()\n",
    "\n",
    "\n",
    "# In[81]:\n",
    "\n",
    "merged_summary_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       ..., \n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "epoch = 0\n",
    "batch = 512\n",
    "\n",
    "print (\"new training, 11 29, 2017\")\n",
    "num_epoch = 100\n",
    "while epoch<num_epoch-1:\n",
    "    start = epoch*batch\n",
    "    end = (epoch + 1)*batch\n",
    "    feed_dict = {placeholder_variable['bd']:transformer_value['bd'][start:end], \n",
    "                 placeholder_variable['city']:transformer_value['city'][start:end],\n",
    "                 placeholder_variable['expiration_date']:transformer_value['expiration_date'][start:end],\n",
    "                 placeholder_variable['gender']:transformer_value['gender'][start:end],\n",
    "                 placeholder_variable['name']:transformer_value['name'][start:end],\n",
    "                 placeholder_variable['registered_via']:transformer_value['registered_via'][start:end],\n",
    "                 placeholder_variable['registration_init_time']:transformer_value['registration_init_time'][start:end],\n",
    "                 placeholder_variable['source_screen_name']:transformer_value['source_screen_name'][start:end],\n",
    "                 placeholder_variable['source_system_tab']:transformer_value['source_system_tab'][start:end],\n",
    "                 placeholder_variable['source_type']:transformer_value['source_type'][start:end],\n",
    "                 y:YY[start:end]\n",
    "                 }\n",
    "\n",
    "    _, c, pre, summary = sess.run([optimizer_train, cost, accuracy, merged_summary_op],\n",
    "                                  feed_dict= feed_dict)\n",
    "    summary_writer.add_summary(summary, epoch)\n",
    "\n",
    "    start_test = count_train + 1 - 10\n",
    "    feed_dict = {placeholder_variable['bd']:transformer_value['bd'][start_test:], \n",
    "             placeholder_variable['city']:transformer_value['city'][start_test:],\n",
    "             placeholder_variable['expiration_date']:transformer_value['expiration_date'][start_test:],\n",
    "             placeholder_variable['gender']:transformer_value['gender'][start_test:],\n",
    "             placeholder_variable['name']:transformer_value['name'][start_test:],\n",
    "             placeholder_variable['registered_via']:transformer_value['registered_via'][start_test:],\n",
    "             placeholder_variable['registration_init_time']:transformer_value['registration_init_time'][start_test:],\n",
    "             placeholder_variable['source_screen_name']:transformer_value['source_screen_name'][start_test:],\n",
    "             placeholder_variable['source_system_tab']:transformer_value['source_system_tab'][start_test:],\n",
    "             placeholder_variable['source_type']:transformer_value['source_type'][start_test:],\n",
    "             y:YY[start_test:]\n",
    "             }\n",
    "    test_temp_accuracy = sess.run(accuracy, feed_dict= feed_dict)\n",
    "    loss_list.append(test_temp_accuracy)\n",
    "    if epoch%100 ==0:\n",
    "        print('Accuarcy = ' + str(test_temp_accuracy))\n",
    "        print('accuracy training is = ' + str(test_temp_accuracy))\n",
    "\n",
    "    epoch +=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_value = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # prediction value\n",
    "\n",
    "start_test = 0\n",
    "feed_dict = {placeholder_variable['bd']:transformer_value_test['bd'][start_test:],\n",
    "             placeholder_variable['city']:transformer_value_test['city'][start_test:],\n",
    "             placeholder_variable['expiration_date']:transformer_value_test['expiration_date'][start_test:],\n",
    "             placeholder_variable['gender']:transformer_value_test['gender'][start_test:],\n",
    "             placeholder_variable['name']:transformer_value_test['name'][start_test:],\n",
    "             placeholder_variable['registered_via']:transformer_value_test['registered_via'][start_test:],\n",
    "             placeholder_variable['registration_init_time']:transformer_value_test['registration_init_time'][start_test:],\n",
    "             placeholder_variable['source_screen_name']:transformer_value_test['source_screen_name'][start_test:],\n",
    "             placeholder_variable['source_system_tab']:transformer_value_test['source_system_tab'][start_test:],\n",
    "             placeholder_variable['source_type']:transformer_value_test['source_type'][start_test:]\n",
    "             }\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = sess.run(out_layer, feed_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.50460219,  0.50809091,  0.52909994, ...,  0.50286579,\n",
       "        0.47801256,  0.47801256], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = song_user_test['id'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing output to file\n",
    "subm = pd.DataFrame()\n",
    "subm['id'] = ids\n",
    "subm['target'] = classification[:,1]\n",
    "subm.to_csv(data_path + 'deep_learning_1.csv.gz', compression = 'gzip', index=False, float_format = '%.5f')\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
